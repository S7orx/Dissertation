{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b8f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fada5fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saharawaji/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/saharawaji/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "from langdetect import DetectorFactory, detect\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211784bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f4f786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811769</th>\n",
       "      <td>2987947</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n",
       "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811770</th>\n",
       "      <td>2987948</td>\n",
       "      <td>823869</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
       "      <td>@115714 wtf!? Iâ€™ve been having really shitty s...</td>\n",
       "      <td>2987947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811771</th>\n",
       "      <td>2812240</td>\n",
       "      <td>121673</td>\n",
       "      <td>True</td>\n",
       "      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n",
       "      <td>@143549 @sprintcare You have to go to https://...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2812239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811772</th>\n",
       "      <td>2987949</td>\n",
       "      <td>AldiUK</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n",
       "      <td>@823870 Sounds delicious, Sarah! ðŸ˜‹ https://t.c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811773</th>\n",
       "      <td>2987950</td>\n",
       "      <td>823870</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
       "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
       "      <td>2987951,2987949</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2811774 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   author_id  inbound                      created_at  \\\n",
       "0               1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1               2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2               3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3               4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4               5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "...           ...         ...      ...                             ...   \n",
       "2811769   2987947  sprintcare    False  Wed Nov 22 08:43:51 +0000 2017   \n",
       "2811770   2987948      823869     True  Wed Nov 22 08:35:16 +0000 2017   \n",
       "2811771   2812240      121673     True  Thu Nov 23 04:13:07 +0000 2017   \n",
       "2811772   2987949      AldiUK    False  Wed Nov 22 08:31:24 +0000 2017   \n",
       "2811773   2987950      823870     True  Tue Nov 21 22:01:04 +0000 2017   \n",
       "\n",
       "                                                      text response_tweet_id  \\\n",
       "0        @115712 I understand. I would like to assist y...                 2   \n",
       "1            @sprintcare and how do you propose we do that               NaN   \n",
       "2        @sprintcare I have sent several private messag...                 1   \n",
       "3        @115712 Please send us a Private Message so th...                 3   \n",
       "4                                       @sprintcare I did.                 4   \n",
       "...                                                    ...               ...   \n",
       "2811769  @823869 Hey, we'd be happy to look into this f...               NaN   \n",
       "2811770  @115714 wtf!? Iâ€™ve been having really shitty s...           2987947   \n",
       "2811771  @143549 @sprintcare You have to go to https://...               NaN   \n",
       "2811772  @823870 Sounds delicious, Sarah! ðŸ˜‹ https://t.c...               NaN   \n",
       "2811773  @AldiUK  warm sloe gin mince pies with ice cre...   2987951,2987949   \n",
       "\n",
       "         in_response_to_tweet_id  \n",
       "0                            3.0  \n",
       "1                            1.0  \n",
       "2                            4.0  \n",
       "3                            5.0  \n",
       "4                            6.0  \n",
       "...                          ...  \n",
       "2811769                2987948.0  \n",
       "2811770                      NaN  \n",
       "2811771                2812239.0  \n",
       "2811772                2987950.0  \n",
       "2811773                      NaN  \n",
       "\n",
       "[2811774 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twcs = pd.read_csv(\"/Users/saharawaji/Documents/GitHub/Research/twcs 2.csv\", on_bad_lines='skip')\n",
    "df_twcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afe637d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet_id', 'author_id', 'inbound', 'created_at', 'text',\n",
      "       'response_tweet_id', 'in_response_to_tweet_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = df_twcs.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694ea01",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ea687e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2811774 entries, 0 to 2811773\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   tweet_id                 int64  \n",
      " 1   author_id                object \n",
      " 2   inbound                  bool   \n",
      " 3   created_at               object \n",
      " 4   text                     object \n",
      " 5   response_tweet_id        object \n",
      " 6   in_response_to_tweet_id  float64\n",
      "dtypes: bool(1), float64(1), int64(1), object(4)\n",
      "memory usage: 131.4+ MB\n",
      "None\n",
      "           tweet_id  in_response_to_tweet_id\n",
      "count  2.811774e+06             2.017439e+06\n",
      "mean   1.504565e+06             1.463141e+06\n",
      "std    8.616450e+05             8.665730e+05\n",
      "min    1.000000e+00             1.000000e+00\n",
      "25%    7.601652e+05             7.155105e+05\n",
      "50%    1.507772e+06             1.439805e+06\n",
      "75%    2.253296e+06             2.220646e+06\n",
      "max    2.987950e+06             2.987950e+06\n",
      "   tweet_id   author_id  inbound                      created_at  \\\n",
      "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
      "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
      "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
      "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
      "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
      "\n",
      "                                                text response_tweet_id  \\\n",
      "0  @115712 I understand. I would like to assist y...                 2   \n",
      "1      @sprintcare and how do you propose we do that               NaN   \n",
      "2  @sprintcare I have sent several private messag...                 1   \n",
      "3  @115712 Please send us a Private Message so th...                 3   \n",
      "4                                 @sprintcare I did.                 4   \n",
      "\n",
      "   in_response_to_tweet_id  \n",
      "0                      3.0  \n",
      "1                      1.0  \n",
      "2                      4.0  \n",
      "3                      5.0  \n",
      "4                      6.0  \n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(df_twcs.info())\n",
    "\n",
    "# Get summary statistics of numerical columns\n",
    "print(df_twcs.describe())\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "print(df_twcs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289e51b",
   "metadata": {},
   "source": [
    "### Handling Missing Data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ee3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values (use with caution)\n",
    "df_twcs.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb798e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Impute missing values in the 'tweet_id' column with the mean\n",
    "df_twcs['tweet_id'].fillna(df_twcs['tweet_id'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ff66f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id                   0\n",
      "author_id                  0\n",
      "inbound                    0\n",
      "created_at                 0\n",
      "text                       0\n",
      "response_tweet_id          0\n",
      "in_response_to_tweet_id    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values in each column\n",
    "missing_values_count = df_twcs.isna().sum()\n",
    "\n",
    "# Alternatively, you can use isnull() instead of isna()\n",
    "# missing_values_count = df_twcs.isnull().sum()\n",
    "\n",
    "# Display the count of missing values for each column\n",
    "print(missing_values_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8849dcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "      <td>5,7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811718</th>\n",
       "      <td>2987897</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 06:57:43 +0000 2017</td>\n",
       "      <td>@136417 Sorry to hear that James, did the the ...</td>\n",
       "      <td>2987898</td>\n",
       "      <td>2987899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811728</th>\n",
       "      <td>2987907</td>\n",
       "      <td>nationalrailenq</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu Nov 30 07:38:44 +0000 2017</td>\n",
       "      <td>London bound trains on the route between Broml...</td>\n",
       "      <td>2987906</td>\n",
       "      <td>2987908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811736</th>\n",
       "      <td>2987915</td>\n",
       "      <td>CoxHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu Nov 30 07:27:11 +0000 2017</td>\n",
       "      <td>@823858  Hello, this does not sound good.  Can...</td>\n",
       "      <td>2987916</td>\n",
       "      <td>2987917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811739</th>\n",
       "      <td>2987918</td>\n",
       "      <td>ArgosHelpers</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu Nov 30 07:58:42 +0000 2017</td>\n",
       "      <td>@823859 Hi Natalie that doesn't sound good. Ca...</td>\n",
       "      <td>2987919</td>\n",
       "      <td>2987920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811760</th>\n",
       "      <td>2811285</td>\n",
       "      <td>Safaricom_Care</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 07:13:34 +0000 2017</td>\n",
       "      <td>@783956 Hi, apologies for the inconvenience. T...</td>\n",
       "      <td>2987940</td>\n",
       "      <td>2811283.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>976810 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id        author_id  inbound                      created_at  \\\n",
       "0               1       sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "2               3           115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3               4       sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4               5           115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "5               6       sprintcare    False  Tue Oct 31 21:46:24 +0000 2017   \n",
       "...           ...              ...      ...                             ...   \n",
       "2811718   2987897     VirginTrains    False  Wed Nov 22 06:57:43 +0000 2017   \n",
       "2811728   2987907  nationalrailenq    False  Thu Nov 30 07:38:44 +0000 2017   \n",
       "2811736   2987915          CoxHelp    False  Thu Nov 30 07:27:11 +0000 2017   \n",
       "2811739   2987918     ArgosHelpers    False  Thu Nov 30 07:58:42 +0000 2017   \n",
       "2811760   2811285   Safaricom_Care    False  Wed Nov 22 07:13:34 +0000 2017   \n",
       "\n",
       "                                                      text response_tweet_id  \\\n",
       "0        @115712 I understand. I would like to assist y...                 2   \n",
       "2        @sprintcare I have sent several private messag...                 1   \n",
       "3        @115712 Please send us a Private Message so th...                 3   \n",
       "4                                       @sprintcare I did.                 4   \n",
       "5        @115712 Can you please send us a private messa...               5,7   \n",
       "...                                                    ...               ...   \n",
       "2811718  @136417 Sorry to hear that James, did the the ...           2987898   \n",
       "2811728  London bound trains on the route between Broml...           2987906   \n",
       "2811736  @823858  Hello, this does not sound good.  Can...           2987916   \n",
       "2811739  @823859 Hi Natalie that doesn't sound good. Ca...           2987919   \n",
       "2811760  @783956 Hi, apologies for the inconvenience. T...           2987940   \n",
       "\n",
       "         in_response_to_tweet_id  \n",
       "0                            3.0  \n",
       "2                            4.0  \n",
       "3                            5.0  \n",
       "4                            6.0  \n",
       "5                            8.0  \n",
       "...                          ...  \n",
       "2811718                2987899.0  \n",
       "2811728                2987908.0  \n",
       "2811736                2987917.0  \n",
       "2811739                2987920.0  \n",
       "2811760                2811283.0  \n",
       "\n",
       "[976810 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7aa35ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1834964"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = 2811774 - 976810\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51fbed",
   "metadata": {},
   "source": [
    "### Text Preprocessing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ce1548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Tokenization\n",
    "df_twcs['text'] = df_twcs['text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# Stop word removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_twcs['text'] = df_twcs['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Stemming (or Lemmatization)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "df_twcs['text'] = df_twcs['text'].apply(lambda tokens: [word.lower() for word in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bbf90bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [@, 115712, understand, ., would, like, assist...\n",
       "2          [@, sprintcare, sent, several, private, messag...\n",
       "3          [@, 115712, please, send, us, private, message...\n",
       "4                                         [@, sprintcare, .]\n",
       "5          [@, 115712, please, send, us, private, message...\n",
       "                                 ...                        \n",
       "2811718    [@, 136417, sorry, hear, james, ,, staff, made...\n",
       "2811728    [london, bound, trains, route, bromley, south,...\n",
       "2811736    [@, 823858, hello, ,, sound, good, ., dm, acco...\n",
       "2811739    [@, 823859, hi, natalie, n't, sound, good, ., ...\n",
       "2811760    [@, 783956, hi, ,, apologies, inconvenience, ....\n",
       "Name: text, Length: 976810, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twcs['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895df3dd",
   "metadata": {},
   "source": [
    "# Feature Engineering:\n",
    "\n",
    "1. Text Features:\n",
    "2. Temporal Features:\n",
    "3. Categorical Features:\n",
    "4. Text-Based Features (NLP):\n",
    "5. Interaction Features:\n",
    "6. Domain-Specific Features:\n",
    "7. Feature Scaling:\n",
    "8. Feature Selection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d050539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          16\n",
      "2           9\n",
      "3          16\n",
      "4           3\n",
      "5          12\n",
      "           ..\n",
      "2811718    15\n",
      "2811728    25\n",
      "2811736    19\n",
      "2811739    17\n",
      "2811760    15\n",
      "Name: text_length, Length: 976810, dtype: int64\n",
      "0          16\n",
      "2           9\n",
      "3          16\n",
      "4           3\n",
      "5          12\n",
      "           ..\n",
      "2811718    15\n",
      "2811728    25\n",
      "2811736    19\n",
      "2811739    17\n",
      "2811760    15\n",
      "Name: word_count, Length: 976810, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Text Features:\n",
    "# A. Text Length: Create a feature that represents the length of the text in characters or words.\n",
    "df_twcs['text_length'] = df_twcs['text'].apply(len)\n",
    "print(df_twcs['text_length'])\n",
    "\n",
    "# B. Word Count: Count the number of words in each text.\n",
    "#df_twcs['word_count'] = df_twcs['text'].apply(lambda x: len(x.split()))\n",
    "# Count the number of words in each text (assuming 'text' is a list of tokens)\n",
    "df_twcs['word_count'] = df_twcs['text'].apply(lambda tokens: len(tokens))\n",
    "\n",
    "print(df_twcs['word_count'])\n",
    "\n",
    "# C. Presence of Keywords: Create binary features indicating the presence of specific keywords in the text.\n",
    "keywords = ['important', 'urgent', 'help']\n",
    "for keyword in keywords:\n",
    "    df_twcs[keyword + '_present'] = df_twcs['text'].apply(lambda x: 1 if keyword in x else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4371913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Features of Temporal Order:\n",
    "\n",
    "# A. Extracting Date and Time: Parse 'created_at' if it is in a string format to extract relevant temporal information such as month, day, hour, and so on.\n",
    "\n",
    "#df_twcs['created_at'] = pd.to_datetime(df_twcs['created_at'])\n",
    "df_twcs['created_at'] = pd.to_datetime(df_twcs['created_at'], utc=True)\n",
    "\n",
    "\n",
    "df_twcs['year'] = df_twcs['created_at'].dt.year\n",
    "df_twcs['month'] = df_twcs['created_at'].dt.month\n",
    "\n",
    "# B. Time Since Tweet: Calculate the time elapsed since a tweet was posted relative to a reference date.\n",
    "#reference_date = pd.Timestamp('2024-01-31')\n",
    "reference_date = pd.Timestamp('2024-01-31', tz='UTC')\n",
    "\n",
    "\n",
    "#df_twcs['time_since_posted'] = (reference_date - df_twcs['created_at']).dt.total_seconds()\n",
    "#df_twcs['time_since_posted'] = (reference_date - df_twcs['created_at']).dt.total_seconds()\n",
    "df_twcs['time_since_posted'] = (reference_date - df_twcs['created_at']).dt.total_seconds()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e68de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Categorical Features:\n",
    "# Encoding Categorical Variables: Convert categorical variables like 'author_id' into numerical values using techniques like one-hot encoding or label encoding.\n",
    "\n",
    "\n",
    "df_twcs = pd.get_dummies(df_twcs, columns=['author_id'], prefix='author')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Text-Based Features (NLP):\n",
    "# A. TF-IDF: Compute TF-IDF scores for words in the text to represent their importance.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_twcs['text'])\n",
    "\n",
    "# B. Word Embeddings: Use pre-trained word embeddings (e.g., Word2Vec, GloVe) to convert text into dense vectors.\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "word2vec_model = Word2Vec.load('word2vec.model')\n",
    "\n",
    "def text_to_embedding(text):\n",
    "    words = text.split()\n",
    "    vectors = [word2vec_model[word] for word in words if word in word2vec_model]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "df_twcs['text_embedding'] = df_twcs['text'].apply(text_to_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Interaction Features:\n",
    "# Create interaction features by combining existing features.\n",
    "\n",
    "df_twcs['text_length_word_count_ratio'] = df_twcs['text_length'] / df_twcs['word_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cd6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Domain-Specific Features:\n",
    "\n",
    "# If you have domain-specific knowledge, create features that are relevant to your specific problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe342e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Feature Scaling:\n",
    "\n",
    "# Normalize or scale numerical features if needed using techniques like Min-Max scaling or Standardization.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_twcs[['text_length', 'word_count']] = scaler.fit_transform(df_twcs[['text_length', 'word_count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Feature Selection:\n",
    "\n",
    "# Perform feature selection techniques (e.g., Recursive Feature Elimination, feature importance from tree-based models) to choose the most relevant features for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633300c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78254974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04821189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235c73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cba8561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:04:47 +0000 2017</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>11,13,14</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811765</th>\n",
       "      <td>2987944</td>\n",
       "      <td>823868</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 22 07:43:36 +0000 2017</td>\n",
       "      <td>@AirAsiaSupport \\n\\nI am unable to do web chec...</td>\n",
       "      <td>2987943</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811768</th>\n",
       "      <td>2987946</td>\n",
       "      <td>524544</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 22 08:25:48 +0000 2017</td>\n",
       "      <td>@VirginTrains Hope you are well? Does the 9.30...</td>\n",
       "      <td>2987945</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811770</th>\n",
       "      <td>2987948</td>\n",
       "      <td>823869</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
       "      <td>@115714 wtf!? Iâ€™ve been having really shitty s...</td>\n",
       "      <td>2987947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811771</th>\n",
       "      <td>2812240</td>\n",
       "      <td>121673</td>\n",
       "      <td>True</td>\n",
       "      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n",
       "      <td>@143549 @sprintcare You have to go to https://...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2812239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811773</th>\n",
       "      <td>2987950</td>\n",
       "      <td>823870</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
       "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
       "      <td>2987951,2987949</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1537843 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id author_id  inbound                      created_at  \\\n",
       "1               2    115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2               3    115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "4               5    115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "6               8    115712     True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "8              12    115713     True  Tue Oct 31 22:04:47 +0000 2017   \n",
       "...           ...       ...      ...                             ...   \n",
       "2811765   2987944    823868     True  Wed Nov 22 07:43:36 +0000 2017   \n",
       "2811768   2987946    524544     True  Wed Nov 22 08:25:48 +0000 2017   \n",
       "2811770   2987948    823869     True  Wed Nov 22 08:35:16 +0000 2017   \n",
       "2811771   2812240    121673     True  Thu Nov 23 04:13:07 +0000 2017   \n",
       "2811773   2987950    823870     True  Tue Nov 21 22:01:04 +0000 2017   \n",
       "\n",
       "                                                      text response_tweet_id  \\\n",
       "1            @sprintcare and how do you propose we do that               NaN   \n",
       "2        @sprintcare I have sent several private messag...                 1   \n",
       "4                                       @sprintcare I did.                 4   \n",
       "6                @sprintcare is the worst customer service            9,6,10   \n",
       "8        @sprintcare You gonna magically change your co...          11,13,14   \n",
       "...                                                    ...               ...   \n",
       "2811765  @AirAsiaSupport \\n\\nI am unable to do web chec...           2987943   \n",
       "2811768  @VirginTrains Hope you are well? Does the 9.30...           2987945   \n",
       "2811770  @115714 wtf!? Iâ€™ve been having really shitty s...           2987947   \n",
       "2811771  @143549 @sprintcare You have to go to https://...               NaN   \n",
       "2811773  @AldiUK  warm sloe gin mince pies with ice cre...   2987951,2987949   \n",
       "\n",
       "         in_response_to_tweet_id  \n",
       "1                            1.0  \n",
       "2                            4.0  \n",
       "4                            6.0  \n",
       "6                            NaN  \n",
       "8                           15.0  \n",
       "...                          ...  \n",
       "2811765                      NaN  \n",
       "2811768                      NaN  \n",
       "2811770                      NaN  \n",
       "2811771                2812239.0  \n",
       "2811773                      NaN  \n",
       "\n",
       "[1537843 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbound_chat = df_twcs[df_twcs.inbound]\n",
    "\n",
    "inbound_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e2aa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id_x</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>inbound_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>response_tweet_id_x</th>\n",
       "      <th>in_response_to_tweet_id_x</th>\n",
       "      <th>tweet_id_y</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>inbound_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>response_tweet_id_y</th>\n",
       "      <th>in_response_to_tweet_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "      <td>5,7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:14 +0000 2017</td>\n",
       "      <td>@115712 I would love the chance to review the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:45:59 +0000 2017</td>\n",
       "      <td>@115712 Hello! We never like our customers to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450330</th>\n",
       "      <td>2987942</td>\n",
       "      <td>823867</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 22 07:30:39 +0000 2017</td>\n",
       "      <td>Hai @AirAsiaSupport #asking how many days need...</td>\n",
       "      <td>2987941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987941</td>\n",
       "      <td>AirAsiaSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 07:55:05 +0000 2017</td>\n",
       "      <td>@823867 we have replied you via DM.Thanks-Emir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450331</th>\n",
       "      <td>2987944</td>\n",
       "      <td>823868</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 22 07:43:36 +0000 2017</td>\n",
       "      <td>@AirAsiaSupport \\n\\nI am unable to do web chec...</td>\n",
       "      <td>2987943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987943</td>\n",
       "      <td>AirAsiaSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 07:54:57 +0000 2017</td>\n",
       "      <td>@823868 Sorry but kindly try to clear browser,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450332</th>\n",
       "      <td>2987946</td>\n",
       "      <td>524544</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 22 08:25:48 +0000 2017</td>\n",
       "      <td>@VirginTrains Hope you are well? Does the 9.30...</td>\n",
       "      <td>2987945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987945</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 08:27:34 +0000 2017</td>\n",
       "      <td>@524544 That's a Peak service. The 09:56 is th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450333</th>\n",
       "      <td>2987948</td>\n",
       "      <td>823869</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
       "      <td>@115714 wtf!? Iâ€™ve been having really shitty s...</td>\n",
       "      <td>2987947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987947</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n",
       "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450334</th>\n",
       "      <td>2987950</td>\n",
       "      <td>823870</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
       "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
       "      <td>2987951,2987949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987949</td>\n",
       "      <td>AldiUK</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n",
       "      <td>@823870 Sounds delicious, Sarah! ðŸ˜‹ https://t.c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987950.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1450335 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id_x author_id_x  inbound_x                    created_at_x  \\\n",
       "0                 3      115712       True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "1                 5      115712       True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "2                 8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "3                 8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "4                 8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "...             ...         ...        ...                             ...   \n",
       "1450330     2987942      823867       True  Wed Nov 22 07:30:39 +0000 2017   \n",
       "1450331     2987944      823868       True  Wed Nov 22 07:43:36 +0000 2017   \n",
       "1450332     2987946      524544       True  Wed Nov 22 08:25:48 +0000 2017   \n",
       "1450333     2987948      823869       True  Wed Nov 22 08:35:16 +0000 2017   \n",
       "1450334     2987950      823870       True  Tue Nov 21 22:01:04 +0000 2017   \n",
       "\n",
       "                                                    text_x  \\\n",
       "0        @sprintcare I have sent several private messag...   \n",
       "1                                       @sprintcare I did.   \n",
       "2                @sprintcare is the worst customer service   \n",
       "3                @sprintcare is the worst customer service   \n",
       "4                @sprintcare is the worst customer service   \n",
       "...                                                    ...   \n",
       "1450330  Hai @AirAsiaSupport #asking how many days need...   \n",
       "1450331  @AirAsiaSupport \\n\\nI am unable to do web chec...   \n",
       "1450332  @VirginTrains Hope you are well? Does the 9.30...   \n",
       "1450333  @115714 wtf!? Iâ€™ve been having really shitty s...   \n",
       "1450334  @AldiUK  warm sloe gin mince pies with ice cre...   \n",
       "\n",
       "        response_tweet_id_x  in_response_to_tweet_id_x  tweet_id_y  \\\n",
       "0                         1                        4.0           1   \n",
       "1                         4                        6.0           4   \n",
       "2                    9,6,10                        NaN           6   \n",
       "3                    9,6,10                        NaN           9   \n",
       "4                    9,6,10                        NaN          10   \n",
       "...                     ...                        ...         ...   \n",
       "1450330             2987941                        NaN     2987941   \n",
       "1450331             2987943                        NaN     2987943   \n",
       "1450332             2987945                        NaN     2987945   \n",
       "1450333             2987947                        NaN     2987947   \n",
       "1450334     2987951,2987949                        NaN     2987949   \n",
       "\n",
       "            author_id_y  inbound_y                    created_at_y  \\\n",
       "0            sprintcare      False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1            sprintcare      False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "2            sprintcare      False  Tue Oct 31 21:46:24 +0000 2017   \n",
       "3            sprintcare      False  Tue Oct 31 21:46:14 +0000 2017   \n",
       "4            sprintcare      False  Tue Oct 31 21:45:59 +0000 2017   \n",
       "...                 ...        ...                             ...   \n",
       "1450330  AirAsiaSupport      False  Wed Nov 22 07:55:05 +0000 2017   \n",
       "1450331  AirAsiaSupport      False  Wed Nov 22 07:54:57 +0000 2017   \n",
       "1450332    VirginTrains      False  Wed Nov 22 08:27:34 +0000 2017   \n",
       "1450333      sprintcare      False  Wed Nov 22 08:43:51 +0000 2017   \n",
       "1450334          AldiUK      False  Wed Nov 22 08:31:24 +0000 2017   \n",
       "\n",
       "                                                    text_y  \\\n",
       "0        @115712 I understand. I would like to assist y...   \n",
       "1        @115712 Please send us a Private Message so th...   \n",
       "2        @115712 Can you please send us a private messa...   \n",
       "3        @115712 I would love the chance to review the ...   \n",
       "4        @115712 Hello! We never like our customers to ...   \n",
       "...                                                    ...   \n",
       "1450330     @823867 we have replied you via DM.Thanks-Emir   \n",
       "1450331  @823868 Sorry but kindly try to clear browser,...   \n",
       "1450332  @524544 That's a Peak service. The 09:56 is th...   \n",
       "1450333  @823869 Hey, we'd be happy to look into this f...   \n",
       "1450334  @823870 Sounds delicious, Sarah! ðŸ˜‹ https://t.c...   \n",
       "\n",
       "        response_tweet_id_y  in_response_to_tweet_id_y  \n",
       "0                         2                        3.0  \n",
       "1                         3                        5.0  \n",
       "2                       5,7                        8.0  \n",
       "3                       NaN                        8.0  \n",
       "4                       NaN                        8.0  \n",
       "...                     ...                        ...  \n",
       "1450330                 NaN                  2987942.0  \n",
       "1450331                 NaN                  2987944.0  \n",
       "1450332                 NaN                  2987946.0  \n",
       "1450333                 NaN                  2987948.0  \n",
       "1450334                 NaN                  2987950.0  \n",
       "\n",
       "[1450335 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_outs = pd.merge(inbound_chat, df_twcs, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id')\n",
    "\n",
    "df_in_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d22ff5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess_Dataset:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.last_id = 0\n",
    "        self.conv = []\n",
    "        self.company_name = ''\n",
    "        self.df_convs = pd.DataFrame(columns=['author_id', 'company_name', 'dialog'])\n",
    "        \n",
    "    def add_to_df(self, last_id, author_id, company_name, text_x, text_y):\n",
    "        if (last_id == author_id):\n",
    "            self.conv.append('participant1|'+ \" \".join(filter(lambda x:x[0]!='@', text_x.split())))\n",
    "            self.conv.append('participant2|'+ \" \".join(filter(lambda x:x[0]!='@', text_y.split())))\n",
    "        elif self.last_id != 0:\n",
    "            if len(self.conv) > 0:\n",
    "                id = len(self.df_convs)\n",
    "                self.df_convs.loc[id, 'author_id'] = self.last_id\n",
    "                self.df_convs.loc[id, 'company_name'] = self.company_name\n",
    "                self.df_convs.loc[id, 'dialog'] = self.conv\n",
    "                self.conv = []\n",
    "            self.last_id = author_id\n",
    "            \n",
    "        else:\n",
    "            self.conv.append('participant1|'+ text_x)\n",
    "            self.conv.append('participant2|'+ text_y)\n",
    "            self.last_id = author_id\n",
    "            self.company_name = company_name\n",
    "    def create_df(self):\n",
    "        [self.add_to_df(self.last_id, row[0], row[1], row[2], row[3]) for row in self.df[['author_id_x', 'author_id_y','text_x', 'text_y']].values]\n",
    "        return self.df_convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f974fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    clean_text = []\n",
    "    text = re.sub(\"''\", \"\", text)\n",
    "    text = \" \".join(filter(lambda x:x[0]!='@', text.split())) # Remove the words starts with '@'\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \", text)\n",
    "    clean_text = [wn.lemmatize(word, pos=\"v\") for word in word_tokenize(text.lower()) \n",
    "                  if (word not in stop_words and word not in list(string.punctuation))]\n",
    "    return clean_text\n",
    "    #return \" \".join([word for word in clean_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9c49f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_participants(conversation):\n",
    "    part1_dialog = []\n",
    "    part2_dialog = []\n",
    "    conv_token = []\n",
    "    for conv in conversation:\n",
    "        dialog = conv.split('|')\n",
    "        if dialog[0] == 'participant1':\n",
    "            part1_dialog.append(dialog[1])\n",
    "        else:\n",
    "            part2_dialog.append(dialog[1])\n",
    "            \n",
    "    if (len(part1_dialog) > 0):\n",
    "        part1_str = \" \".join([word for word in part1_dialog])\n",
    "        conv_token.append(clean_text(part1_str))\n",
    "    if (len(part2_dialog) > 0):\n",
    "        part2_str = \" \".join([word for word in part2_dialog])\n",
    "        conv_token.append(clean_text(part2_str))\n",
    "    return conv_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f57c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
